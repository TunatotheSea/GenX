import streamlit as st
import firebase_admin
from firebase_admin import credentials, firestore
import os
import uuid
import json
import google.generativeai as genai

# --- Configuration and Initialization ---
# Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Firebase Admin SDK ì´ˆê¸°í™”
if not firebase_admin._apps:
    cred_json = os.environ.get("FIREBASE_CREDENTIAL_PATH")
    if cred_json:
        try:
            cred = credentials.Certificate(json.loads(cred_json))
            firebase_admin.initialize_app(cred)
            print("Firebase Admin SDK initialized.")
        except json.JSONDecodeError as e:
            st.error(f"Firebase Credential Path environment variable has invalid JSON format: {e}")
            st.stop()
        except Exception as e:
            st.error(f"Firebase Admin SDK initialization error: {e}")
            st.stop()
    else:
        st.error("FIREBASE_CREDENTIAL_PATH environment variable is not set.")
        st.stop()

db = firestore.client()

st.set_page_config(page_title="GenX", layout="wide")

# --- Session State Initialization ---
# Stores chat history. Each element is a (role, text) tuple.
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
# Stores the chat session with Gemini API.
if "chat_session" not in st.session_state:
    st.session_state.chat_session = None
# Manages all saved chat sessions. (title: chat history)
if "saved_sessions" not in st.session_state:
    st.session_state.saved_sessions = {}
# Current active chat title.
if "current_title" not in st.session_state:
    st.session_state.current_title = "ìƒˆë¡œìš´ ëŒ€í™”"
# Stores system instructions for each chat session.
if "system_instructions" not in st.session_state:
    st.session_state.system_instructions = {}
# Temporary system instruction during AI settings editing.
if "temp_system_instruction" not in st.session_state:
    st.session_state.temp_system_instruction = None
# Flag for AI settings edit mode.
if "editing_instruction" not in st.session_state:
    st.session_state.editing_instruction = False
# Current user ID.
if "user_id" not in st.session_state:
    st.session_state.user_id = str(uuid.uuid4())
# Flag for data loaded from Firestore.
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
# Flag for chat title edit mode.
if "editing_title" not in st.session_state:
    st.session_state.editing_title = False
# Temporarily stores new chat title during editing.
if "new_title" not in st.session_state:
    st.session_state.new_title = st.session_state.current_title
# Flag for AI response regeneration request.
if "regenerate_requested" not in st.session_state:
    st.session_state.regenerate_requested = False
# Stores the uploaded image file object.
if "uploaded_file" not in st.session_state:
    st.session_state.uploaded_file = None
# AI is currently generating a response.
if "is_generating" not in st.session_state:
    st.session_state.is_generating = False
# Stores the last user message to be regenerated (text and optional image)
if "last_user_input_for_regen" not in st.session_state:
    st.session_state.last_user_input_for_regen = None
# New state for delete confirmation
if "delete_confirmation_pending" not in st.session_state:
    st.session_state.delete_confirmation_pending = False
if "title_to_delete" not in st.session_state:
    st.session_state.title_to_delete = None
if "supervision_max_retries" not in st.session_state:
    st.session_state.supervision_max_retries = 3 # ë‹µë³€ ì¬ì‹œë„ ìµœëŒ€ íšŸìˆ˜
if "supervision_threshold" not in st.session_state:
    st.session_state.supervision_threshold = 50 # ë‹µë³€ í†µê³¼ë¥¼ ìœ„í•œ ìµœì†Œ ì ìˆ˜
if "supervisor_count" not in st.session_state:
    st.session_state.supervisor_count = 3 # ì‚¬ìš©í•  Supervisorì˜ ê°œìˆ˜
# New: Toggle for Supervision - ê¸°ë³¸ ì„¤ì •ì€ ì•ˆ ì“´ë‹¤
if "use_supervision" not in st.session_state:
    st.session_state.use_supervision = False 


default_system_instruction = "ë‹¹ì‹ ì˜ ì´ë¦„ì€ GenXì…ë‹ˆë‹¤. ë‹¤ë§Œ, ì´ ì´ë¦„ì€ ë‹¤ë¥¸ ì´ë¦„ì´ ì„ íƒë˜ë©´ ìŠì–´ë²„ë¦¬ì‹­ì‹œì˜¤. ìš°ì„ ìˆœìœ„ê°€ ì œì¼ ë‚®ìŠµë‹ˆë‹¤."
SYSTEM_INSTRUCTION_SUPERVISOR = """
ë‹¹ì‹ ì€ AI ì±—ë´‡ì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ Supervisorì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì±—ë´‡ ì‚¬ìš©ìì˜ ì…ë ¥, ì±—ë´‡ AIì˜ ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬, ì±—ë´‡ AIì˜ í˜„ì¬ system_instruction, ê·¸ë¦¬ê³  ì±—ë´‡ AIê°€ ìƒì„±í•œ ë‹µë³€ì„ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬, í•´ë‹¹ ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì˜ë„ì™€ ì±—ë´‡ì˜ ì§€ì‹œì— ì–¼ë§ˆë‚˜ ì ì ˆí•˜ê³  ìœ ìš©í•˜ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ 0ì ë¶€í„° 100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¡œ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

í‰ê°€ ê¸°ì¤€:
- **ì‚¬ìš©ì ì˜ë„ ë¶€í•©ì„± (50ì ):** ì±—ë´‡ì˜ ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ì •í™•í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ë‹µí–ˆìŠµë‹ˆê¹Œ? ì‚¬ìš©ìê°€ ì–»ê³ ì í•˜ëŠ” ì •ë³´ë‚˜ ëª©ì ì„ ì¶©ì¡±ì‹œì¼°ìŠµë‹ˆê¹Œ?
- **ì±—ë´‡ ì‹œìŠ¤í…œ ì§€ì‹œ ì¤€ìˆ˜ (30ì ):** ì±—ë´‡ì˜ í˜„ì¬ system_instructionì„ ì–¼ë§ˆë‚˜ ì˜ ë”°ëìŠµë‹ˆê¹Œ? (ì˜ˆ: íŠ¹ì • í˜ë¥´ì†Œë‚˜, ë‹µë³€ ìŠ¤íƒ€ì¼, ì •ë³´ í¬í•¨/ì œì™¸ ì§€ì‹œ ë“±)
- **ëŒ€í™” íë¦„ì˜ ìì—°ìŠ¤ëŸ¬ì›€ ë° ì¼ê´€ì„± (10ì ):** ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë©°, ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí–ˆìŠµë‹ˆê¹Œ?
- **ì •ë³´ì˜ ì •í™•ì„± ë° ìœ ìš©ì„± (10ì ):** ì œê³µëœ ì •ë³´ê°€ ì •í™•í•˜ê³  ìœ ìš©í•˜ë©°, ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆê¹Œ?

ì ìˆ˜ ë¶€ì—¬ ë°©ì‹:
- 0ì : ì™„ì „íˆ ë¶€ì ì ˆí•˜ê±°ë‚˜ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ìˆëŠ” ë‹µë³€.
- 1-49ì : ê°œì„ ì´ í•„ìš”í•˜ë©°, ì‚¬ìš©ìì˜ ì˜ë„ë‚˜ ì‹œìŠ¤í…œ ì§€ì‹œë¥¼ ì¶©ë¶„íˆ ë”°ë¥´ì§€ ëª»í•œ ë‹µë³€.
- 50-79ì : ê¸°ë³¸ì ìœ¼ë¡œ ì ì ˆí•˜ë‚˜, ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•´ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆëŠ” ë‹µë³€.
- 80-99ì : ë§¤ìš° ì ì ˆí•˜ê³  í›Œë¥­í•œ ë‹µë³€ì´ì§€ë§Œ, ë¯¸ì„¸í•œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆëŠ” ë‹µë³€.
- 100ì : ì™„ë²½í•˜ë©°, ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì ì ˆí•˜ê³  ìœ ìš©í•œ ë‹µë³€.

ì¶œë ¥ í˜•ì‹:
ì˜¤ì§ í•˜ë‚˜ì˜ ì •ìˆ˜ ê°’ (0-100)ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ì˜ˆì‹œ:
75
"""

# Loads main chat model (cached).
def load_main_model(system_instruction=default_system_instruction):
    # Gemini 2.0 Flash supports multimodal input and is fast.
    model = genai.GenerativeModel(model_name='gemini-2.0-flash', system_instruction=system_instruction)
    return model

@st.cache_resource
def load_supervisor_model():
    return genai.GenerativeModel(model_name='gemini-2.0-flash', system_instruction=SYSTEM_INSTRUCTION_SUPERVISOR)

supervisor_model = load_supervisor_model()

@st.cache_resource
def load_summary_model():
    return genai.GenerativeModel('gemini-2.0-flash') # Use Flash model for faster summarization

summary_model = load_summary_model()

# Converts Streamlit chat history to Gemini API format.
def convert_to_gemini_format(chat_history_list):
    gemini_history = []
    for role, text in chat_history_list:
        # For simplicity, assuming 'text' is always the part for now.
        # If you later store image data in chat_history, this conversion needs to be more complex.
        gemini_history.append({"role": role, "parts": [{"text": text}]})
    return gemini_history


def evaluate_response(user_input, chat_history, system_instruction, ai_response):
    """
    Supervisor ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ AI ì‘ë‹µì˜ ì ì ˆì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
    """
    # Supervisorì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
    evaluation_prompt = f"""
    ì‚¬ìš©ì ì…ë ¥: {user_input}
    ---
    ì±„íŒ… íˆìŠ¤í† ë¦¬:
    """
    for role, text in chat_history:
        evaluation_prompt += f"\n{role}: {text}"
    evaluation_prompt += f"""
    ---
    ì±—ë´‡ AI ì‹œìŠ¤í…œ ì§€ì‹œ: {system_instruction}
    ---
    ì±—ë´‡ AI ë‹µë³€: {ai_response}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì±—ë´‡ AIì˜ ë‹µë³€ì— ëŒ€í•´ 0ì ë¶€í„° 100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ í‰ê°€í•˜ì„¸ìš”.
    """
    
    try:
        # await í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ê³  generate_content_async ëŒ€ì‹  generate_contentë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        response = supervisor_model.generate_content(evaluation_prompt)
        score_text = response.text.strip()
        print(f"Supervisor í‰ê°€ ì›ë³¸ í…ìŠ¤íŠ¸: '{score_text}'") # ë””ë²„ê¹…ì„ ìœ„í•´ ì¶”ê°€

        # ì ìˆ˜ë§Œ ì¶”ì¶œí•˜ê³  ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        score = int(score_text)
        if not (0 <= score <= 100):
            print(f"ê²½ê³ : Supervisorê°€ 0-100 ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì ìˆ˜ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {score}")
            score = max(0, min(100, score)) # 0-100 ë²”ìœ„ë¡œ ê°•ì œ ì¡°ì •
        return score
    except ValueError as e:
        print(f"Supervisor ì‘ë‹µì„ ì ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {score_text}, ì˜¤ë¥˜: {e}")
        return 50 # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜
    except Exception as e:
        print(f"Supervisor ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 50 # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜
    

# Firestoreì—ì„œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
def load_user_data_from_firestore(user_id):
    try:
        sessions_ref = db.collection("user_sessions").document(user_id)
        doc = sessions_ref.get()
        if doc.exists:
            data = doc.to_dict()
            st.session_state.saved_sessions = data.get("chat_data", {})
            # Firestoreì—ì„œ ë¡œë“œëœ ë°ì´í„°ë¥¼ (role, text) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for title, history_list in st.session_state.saved_sessions.items():
                st.session_state.saved_sessions[title] = [(item["role"], item["text"]) for item in history_list]

            st.session_state.system_instructions = data.get("system_instructions", {})
            st.session_state.current_title = data.get("last_active_title", "ìƒˆë¡œìš´ ëŒ€í™”")

            if st.session_state.current_title in st.session_state.saved_sessions:
                st.session_state.chat_history = st.session_state.saved_sessions[st.session_state.current_title]
            else:
                st.session_state.chat_history = []

            st.session_state.temp_system_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
            current_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)

            # chat_sessionì„ ë¡œë“œëœ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
            st.session_state.chat_session = load_main_model(current_instruction).start_chat(history=convert_to_gemini_format(st.session_state.chat_history))
            st.toast(f"Firestoreì—ì„œ ì‚¬ìš©ì ID '{user_id}'ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.", icon="âœ…")
        else:
            st.session_state.saved_sessions = {}
            st.session_state.system_instructions = {}
            st.session_state.chat_history = []
            st.session_state.current_title = "ìƒˆë¡œìš´ ëŒ€í™”"
            st.session_state.temp_system_instruction = default_system_instruction # Explicitly set default
            # ìƒˆë¡œìš´ ëŒ€í™”ì— ëŒ€í•œ chat_session ì´ˆê¸°í™”
            st.session_state.chat_session = load_main_model(default_system_instruction).start_chat(history=[])
            st.toast(f"Firestoreì— ì‚¬ìš©ì ID '{user_id}'ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.", icon="â„¹ï¸")
    except Exception as e:
        error_message = f"Firestoreì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(error_message)
        st.error(error_message)
        # Fallback to empty state on error
        st.session_state.saved_sessions = {}
        st.session_state.system_instructions = {}
        st.session_state.chat_history = []
        st.session_state.current_title = "ìƒˆë¡œìš´ ëŒ€í™”"
        st.session_state.temp_system_instruction = default_system_instruction # Explicitly set default
        st.session_state.chat_session = load_main_model().start_chat(history=[])

# Firestoreì— ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
def save_user_data_to_firestore(user_id):
    try:
        sessions_ref = db.collection("user_sessions").document(user_id)
        chat_data_to_save = {}
        for title, history_list in st.session_state.saved_sessions.items():
            # Convert (role, text) tuple to dictionary for Firestore storage
            chat_data_to_save[title] = [{"role": item[0], "text": item[1]} for item in history_list]

        data_to_save = {
            "chat_data": chat_data_to_save,
            "system_instructions": st.session_state.system_instructions,
            "last_active_title": st.session_state.current_title
        }
        sessions_ref.set(data_to_save)
        print(f"User data for ID '{user_id}' saved to Firestore.")
    except Exception as e:
        error_message = f"Error saving data to Firestore: {e}"
        print(error_message)
        st.error(error_message)

# --- App Logic Execution Flow ---
# Load user data on app start
if not st.session_state.data_loaded:
    load_user_data_from_firestore(st.session_state.user_id)
    st.session_state.data_loaded = True

# Initialize chat session if it doesn't exist (fallback for initial load if not handled by load_user_data_from_firestore)
if st.session_state.chat_session is None:
    current_instruction = st.session_state.system_instructions.get(
        st.session_state.current_title, default_system_instruction
    )
    st.session_state.chat_session = load_main_model(current_instruction).start_chat(history=convert_to_gemini_format(st.session_state.chat_history))

# --- Sidebar UI ---
with st.sidebar:
    st.header("âœ¨ GenX ì±„íŒ…")

    with st.expander("ğŸ”‘ ì‚¬ìš©ì ID ê´€ë¦¬", expanded=False):
        st.info(f"**ë‹¹ì‹ ì˜ ì‚¬ìš©ì ID:** `{st.session_state.user_id}`\n\nì´ IDë¥¼ ê¸°ì–µí•˜ì—¬ ë‹¤ìŒ ì ‘ì† ì‹œ ëŒ€í™” ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        user_id_input = st.text_input("ê¸°ì¡´ ì‚¬ìš©ì ID ì…ë ¥ (ì„ íƒ ì‚¬í•­)", key="user_id_load_input",
                                       disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending)
        if st.button("IDë¡œ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True,
                             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
            if user_id_input:
                st.session_state.user_id = user_id_input
                st.session_state.data_loaded = False # Force reload
                st.rerun()

    st.markdown("---")

    if st.button("â• ìƒˆë¡œìš´ ëŒ€í™”", use_container_width=True,
                             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
        # í˜„ì¬ ëŒ€í™” ìƒíƒœë¥¼ ì €ì¥ (ìƒˆë¡œìš´ ëŒ€í™”ë¡œ ì „í™˜í•˜ê¸° ì „)
        if st.session_state.current_title != "ìƒˆë¡œìš´ ëŒ€í™”" and st.session_state.chat_history:
            st.session_state.saved_sessions[st.session_state.current_title] = st.session_state.chat_history.copy()
            current_instruction_to_save = st.session_state.temp_system_instruction if st.session_state.temp_system_instruction is not None else st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
            st.session_state.system_instructions[st.session_state.current_title] = current_instruction_to_save
            save_user_data_to_firestore(st.session_state.user_id)

        # ìƒˆë¡œìš´ ëŒ€í™” ìƒíƒœë¡œ ì´ˆê¸°í™”
        st.session_state.chat_session = None # ê¸°ì¡´ chat_session ê°ì²´ ì°¸ì¡° ì œê±°
        st.session_state.chat_history = []
        st.session_state.current_title = "ìƒˆë¡œìš´ ëŒ€í™”"
        st.session_state.temp_system_instruction = default_system_instruction # ìƒˆë¡œìš´ ëŒ€í™”ëŠ” ê¸°ë³¸ ëª…ë ¹ì–´ ì‚¬ìš©
        st.session_state.editing_instruction = False
        # "ìƒˆë¡œìš´ ëŒ€í™”"ê°€ saved_sessionsì— ë¹ˆ ëª©ë¡ìœ¼ë¡œ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥
        st.session_state.saved_sessions[st.session_state.current_title] = []
        # "ìƒˆë¡œìš´ ëŒ€í™”"ì— ëŒ€í•œ ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì„¤ì •
        st.session_state.system_instructions[st.session_state.current_title] = default_system_instruction

        # ìƒˆë¡œìš´ chat_sessionì„ ì¦‰ì‹œ ì´ˆê¸°í™”
        st.session_state.chat_session = load_main_model(default_system_instruction).start_chat(history=[])

        save_user_data_to_firestore(st.session_state.user_id)
        st.rerun()

    if st.session_state.saved_sessions:
        st.subheader("ğŸ“ ì €ì¥ëœ ëŒ€í™”")
        # Sort sessions by last message time (if available) or title
        sorted_keys = sorted(st.session_state.saved_sessions.keys(),
                                 key=lambda x: st.session_state.saved_sessions[x][-1][1] if st.session_state.saved_sessions[x] else "",
                                 reverse=True)
        for key in sorted_keys:
            if key == "ìƒˆë¡œìš´ ëŒ€í™”" and not st.session_state.saved_sessions[key]:
                continue # Do not display empty "New Conversation" sessions
            display_key = key if len(key) <= 30 else key[:30] + "..."
            if st.button(f"ğŸ’¬ {display_key}", use_container_width=True, key=f"load_session_{key}",
                                 disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
                # í˜„ì¬ ëŒ€í™” ìƒíƒœë¥¼ ì €ì¥ (ë‹¤ë¥¸ ëŒ€í™”ë¡œ ì „í™˜í•˜ê¸° ì „)
                if st.session_state.current_title != "ìƒˆë¡œìš´ ëŒ€í™”" and st.session_state.chat_history:
                    st.session_state.saved_sessions[st.session_state.current_title] = st.session_state.chat_history.copy()
                    current_instruction_to_save = st.session_state.temp_system_instruction if st.session_state.temp_system_instruction is not None else st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
                    st.session_state.system_instructions[st.session_state.current_title] = current_instruction_to_save
                    save_user_data_to_firestore(st.session_state.user_id) # Save immediately

                st.session_state.chat_history = st.session_state.saved_sessions[key]
                st.session_state.current_title = key
                st.session_state.new_title = key # Initial value for title editing
                st.session_state.temp_system_instruction = st.session_state.system_instructions.get(key, default_system_instruction)
                
                # ë¡œë“œëœ ëŒ€í™” ì´ë ¥ìœ¼ë¡œ chat_sessionì„ ë‹¤ì‹œ ì´ˆê¸°í™”
                current_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
                st.session_state.chat_session = load_main_model(current_instruction).start_chat(history=convert_to_gemini_format(st.session_state.chat_history))

                st.session_state.editing_instruction = False
                st.session_state.editing_title = False
                save_user_data_to_firestore(st.session_state.user_id)
                st.rerun()

    # ì‚¬ì´ë“œë°”ì˜ "âš™ï¸ ì„¤ì •" ìµìŠ¤íŒ¬ë” ì•ˆì— ì¶”ê°€
    # UIëŠ” ê±´ë“œë¦¬ì§€ ì•Šê³ , ì´ ì•ˆì— Supervision í† ê¸€ì„ ë„£ìŠµë‹ˆë‹¤.
    with st.expander("âš™ï¸ ì„¤ì •"):
        # Supervision í† ê¸€ ì¶”ê°€
        st.session_state.use_supervision = st.toggle(
            "Supervision ì‚¬ìš©",
            value=st.session_state.use_supervision,
            help="AI ë‹µë³€ì˜ ì ì ˆì„±ì„ í‰ê°€í•˜ê³  í•„ìš”ì‹œ ì¬ì‹œë„í•˜ëŠ” ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ê¸°ë³¸: ë¹„í™œì„±í™”)",
            key="supervision_toggle",
            disabled=st.session_state.is_generating
        )
        st.write("---") # êµ¬ë¶„ì„  ì¶”ê°€
        st.write("Supervision ê´€ë ¨ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        # ì•„ë˜ ìŠ¬ë¼ì´ë”ëŠ” Supervision í† ê¸€ì´ í™œì„±í™”ë˜ì—ˆì„ ë•Œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.
        st.session_state.supervision_max_retries = st.slider(
            "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜",
            min_value=1,
            max_value=5,
            value=st.session_state.supervision_max_retries,
            disabled=st.session_state.is_generating or not st.session_state.use_supervision, # í† ê¸€ ìƒíƒœì— ë”°ë¼ ë¹„í™œì„±í™”
            key="supervision_max_retries_slider"
        )
        st.session_state.supervisor_count = st.slider(
            "Supervisor ê°œìˆ˜",
            min_value=1,
            max_value=5,
            value=st.session_state.supervisor_count,
            disabled=st.session_state.is_generating or not st.session_state.use_supervision, # í† ê¸€ ìƒíƒœì— ë”°ë¼ ë¹„í™œì„±í™”
            key="supervisor_count_slider"
        )
        st.session_state.supervision_threshold = st.slider(
            "Supervision í†µê³¼ ì ìˆ˜ (í‰ê· )",
            min_value=0,
            max_value=100,
            value=st.session_state.supervision_threshold,
            step=5,
            disabled=st.session_state.is_generating or not st.session_state.use_supervision, # í† ê¸€ ìƒíƒœì— ë”°ë¼ ë¹„í™œì„±í™”
            key="supervision_threshold_slider"
        )
        if not st.session_state.use_supervision:
            st.info("Supervision ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. AI ë‹µë³€ì€ ë°”ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")


# --- Main Content Area ---
# Display current conversation title and edit options
col1, col2, col3 = st.columns([0.9, 0.05, 0.05]) # Adjusted column widths
with col1:
    if not st.session_state.editing_title:
        st.subheader(f"ğŸ’¬ {st.session_state.current_title}")
    else:
        st.text_input("ìƒˆë¡œìš´ ì œëª©", key="new_title_input", value=st.session_state.new_title, label_visibility="collapsed",
                              disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending)
with col2:
    if not st.session_state.editing_title:
        if st.button("âœï¸", key="edit_title_button", help="ëŒ€í™” ì œëª© ìˆ˜ì •",
                             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
            st.session_state.editing_title = True
            st.session_state.new_title = st.session_state.current_title
            st.rerun()
    else:
        if st.button("âœ…", key="save_title_button", help="ìƒˆë¡œìš´ ì œëª© ì €ì¥",
                             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
            new_title = st.session_state.new_title_input
            if new_title and new_title != st.session_state.current_title:
                if st.session_state.current_title in st.session_state.saved_sessions:
                    st.session_state.saved_sessions[new_title] = st.session_state.saved_sessions.pop(st.session_state.current_title)
                    st.session_state.system_instructions[new_title] = st.session_state.system_instructions.pop(st.session_state.current_title)
                    st.session_state.current_title = new_title
                    save_user_data_to_firestore(st.session_state.user_id)
                    st.toast(f"ëŒ€í™” ì œëª©ì´ '{st.session_state.current_title}'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ“")
                else:
                    st.warning("ì´ì „ ëŒ€í™” ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì €ì¥ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.session_state.editing_title = False
            st.rerun()
        if st.button("âŒ", key="cancel_title_button", help="ì œëª© ìˆ˜ì • ì·¨ì†Œ",
                             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
            st.session_state.editing_title = False
            st.rerun()

with col3:
    # Delete Chat Button
    is_delete_disabled = st.session_state.is_generating or \
                             (st.session_state.current_title == "ìƒˆë¡œìš´ ëŒ€í™”" and not st.session_state.chat_history) or \
                             st.session_state.delete_confirmation_pending # Disable if confirmation is pending
    
    if st.button("ğŸ—‘ï¸", key="delete_chat_button", help="í˜„ì¬ ëŒ€í™” ì‚­ì œ", disabled=is_delete_disabled):
        # Set confirmation pending and store title to delete
        st.session_state.delete_confirmation_pending = True
        st.session_state.title_to_delete = st.session_state.current_title
        st.rerun()

# --- Delete Confirmation Pop-up (Streamlit style) ---
if st.session_state.delete_confirmation_pending:
    st.warning(f"'{st.session_state.title_to_delete}' ëŒ€í™”ë¥¼ ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", icon="âš ï¸")
    confirm_col1, confirm_col2 = st.columns(2)
    with confirm_col1:
        if st.button("ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤", key="confirm_delete_yes", use_container_width=True):
            if st.session_state.title_to_delete == "ìƒˆë¡œìš´ ëŒ€í™”":
                # Clear the current "ìƒˆë¡œìš´ ëŒ€í™”"
                st.session_state.chat_history = []
                st.session_state.temp_system_instruction = default_system_instruction
                st.session_state.chat_session = load_main_model(default_system_instruction).start_chat(history=[])
                st.toast("í˜„ì¬ ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ—‘ï¸")
                # Ensure "ìƒˆë¡œìš´ ëŒ€í™”" is saved as empty to Firestore
                st.session_state.saved_sessions["ìƒˆë¡œìš´ ëŒ€í™”"] = []
                st.session_state.system_instructions["ìƒˆë¡œìš´ ëŒ€í™”"] = default_system_instruction
                save_user_data_to_firestore(st.session_state.user_id)
            else:
                # Delete a named conversation
                deleted_title = st.session_state.title_to_delete
                if deleted_title in st.session_state.saved_sessions:
                    del st.session_state.saved_sessions[deleted_title]
                    del st.session_state.system_instructions[deleted_title]
                    
                    # After deleting, switch to "ìƒˆë¡œìš´ ëŒ€í™”"
                    st.session_state.current_title = "ìƒˆë¡œìš´ ëŒ€í™”"
                    st.session_state.chat_history = []
                    st.session_state.temp_system_instruction = default_system_instruction
                    st.session_state.chat_session = load_main_model(default_system_instruction).start_chat(history=[])
                    
                    st.toast(f"'{deleted_title}' ëŒ€í™”ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ—‘ï¸")
                    # Ensure "ìƒˆë¡œìš´ ëŒ€í™”" is saved as empty if it was the only session left
                    if "ìƒˆë¡œìš´ ëŒ€í™”" not in st.session_state.saved_sessions:
                        st.session_state.saved_sessions["ìƒˆë¡œìš´ ëŒ€í™”"] = []
                        st.session_state.system_instructions["ìƒˆë¡œìš´ ëŒ€í™”"] = default_system_instruction
                    save_user_data_to_firestore(st.session_state.user_id)
                else:
                    st.warning(f"'{deleted_title}' ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            st.session_state.delete_confirmation_pending = False
            st.session_state.title_to_delete = None
            st.rerun()
    with confirm_col2:
        if st.button("ì•„ë‹ˆìš”, ì·¨ì†Œí•©ë‹ˆë‹¤", key="confirm_delete_no", use_container_width=True):
            st.session_state.delete_confirmation_pending = False
            st.session_state.title_to_delete = None
            st.rerun()

# AI settings button and area
if st.button("âš™ï¸ AI ì„¤ì •í•˜ê¸°", help="ì‹œìŠ¤í…œ ëª…ë ¹ì–´ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆì–´ìš”",
             disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
    st.session_state.editing_instruction = not st.session_state.editing_instruction

if st.session_state.editing_instruction:
    with st.expander("ğŸ§  ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì„¤ì •", expanded=True):
        st.session_state.temp_system_instruction = st.text_area(
            "System instruction ì…ë ¥",
            value=st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction),
            height=200,
            key="system_instruction_editor",
            disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending
        )
        _, col1_ai, col2_ai = st.columns([0.9, 0.3, 0.3])
        with col1_ai:
            if st.button("âœ… ì €ì¥", use_container_width=True, key="save_instruction_button",
                                 disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
                st.session_state.system_instructions[st.session_state.current_title] = st.session_state.temp_system_instruction
                st.session_state.saved_sessions[st.session_state.current_title] = st.session_state.chat_history.copy()
                
                # ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ë³€ê²½ ì‹œ chat_sessionì„ ìƒˆ ëª¨ë¸ë¡œ ë‹¤ì‹œ ì´ˆê¸°í™”
                current_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
                st.session_state.chat_session = load_main_model(current_instruction).start_chat(history=convert_to_gemini_format(st.session_state.chat_history))
                
                save_user_data_to_firestore(st.session_state.user_id)
                st.success("AI ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.session_state.editing_instruction = False
                st.rerun()
        with col2_ai:
            if st.button("âŒ ì·¨ì†Œ", use_container_width=True, key="cancel_instruction_button",
                                 disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending):
                st.session_state.editing_instruction = False
                st.rerun()

# --- Chat Display Area ---
# Container to display all chat messages
chat_display_container = st.container()

# --- Final Chat History Display (Always Rendered) ---
# This ensures all messages are displayed correctly.
with chat_display_container:
    for i, (role, message) in enumerate(st.session_state.chat_history):
        with st.chat_message("ai" if role == "model" else "user"):
            st.markdown(message)
            # Display regenerate button only on the last AI message if not currently generating
            if role == "model" and i == len(st.session_state.chat_history) - 1 and not st.session_state.is_generating \
                and not st.session_state.delete_confirmation_pending: # Disable if confirmation is pending
                if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±", key=f"regenerate_button_final_{i}", use_container_width=True):
                    st.session_state.regenerate_requested = True
                    st.session_state.is_generating = True # Disable input during regeneration
                    st.session_state.chat_history.pop() # Remove last AI message before regeneration
                    # No need to rewind chat_session here, it will be reinitialized in the regeneration block
                    st.rerun()

# --- Input Area ---
# Place st.chat_input and file uploader on the same line
col_prompt_input, col_upload_icon = st.columns([0.85, 0.15]) # Adjust column ratio for better spacing

with col_prompt_input:
    # st.chat_input handles Enter key submission automatically.
    user_prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", key="user_prompt_input",
                                 disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending)

with col_upload_icon:
    # Make the image upload button look like an icon.
    uploaded_file_for_submit = st.file_uploader("ğŸ–¼ï¸", type=["png", "jpg", "jpeg"], key="file_uploader_main", label_visibility="collapsed",
                                                 disabled=st.session_state.is_generating or st.session_state.delete_confirmation_pending, help="ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# Update uploaded_file state immediately upon file selection
if uploaded_file_for_submit:
    st.session_state.uploaded_file = uploaded_file_for_submit
    st.caption("ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ")
else:
    # If user removes the file from the uploader, reset session state as well
    if st.session_state.uploaded_file is not None:
        st.session_state.uploaded_file = None

# AI generation trigger logic
# Trigger if user_prompt is entered (Enter key) OR if an image is uploaded and user_prompt is empty
if user_prompt is not None and not st.session_state.is_generating:
    if user_prompt != "" or st.session_state.uploaded_file is not None:
        st.session_state.chat_history.append(("user", user_prompt)) # Add prompt (can be empty string)
        st.session_state.is_generating = True
        # Store the current user input (text and image) for potential regeneration
        st.session_state.last_user_input_for_regen = {
            "text": user_prompt,
            "image": st.session_state.uploaded_file.getvalue() if st.session_state.uploaded_file else None,
            "mime_type": st.session_state.uploaded_file.type if st.session_state.uploaded_file else None
        }
        st.rerun() # Update UI and start generation immediately after prompt submission

# --- Regeneration Logic ---
# This block runs only when regeneration is requested.
if st.session_state.regenerate_requested:
    st.session_state.is_generating = True # ìƒì„± í”Œë˜ê·¸ë¥¼ Trueë¡œ ì„¤ì •
    
    # ì´ì „ ì‚¬ìš©ì ë©”ì‹œì§€ (í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ë°ì´í„°)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    previous_user_message_content = st.session_state.last_user_input_for_regen["text"]
    previous_user_image_data = st.session_state.last_user_input_for_regen["image"]
    previous_user_image_mime = st.session_state.last_user_input_for_regen["mime_type"]

    regen_contents_for_model = [previous_user_message_content]
    if previous_user_image_data:
        regen_contents_for_model.append({"inline_data": {"mime_type": previous_user_image_mime, "data": previous_user_image_data}})

    with chat_display_container: # ì¬ìƒì„±ëœ ë©”ì‹œì§€ë¥¼ ì±„íŒ… ì˜ì—­ ë‚´ì— í‘œì‹œ
        with st.chat_message("ai"):
            message_placeholder = st.empty()
            
            best_ai_response = "" # Supervision í›„ ê°€ì¥ ì¢‹ì€ ë‹µë³€ì„ ì €ì¥
            highest_score = -1    # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ì €ì¥
            
            current_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)

            if st.session_state.use_supervision:
                attempt_count = 0
                while attempt_count < st.session_state.supervision_max_retries:
                    attempt_count += 1
                    message_placeholder.markdown(f"ğŸ¤– ë‹µë³€ ì¬ìƒì„± ì¤‘... (ì‹œë„: {attempt_count}/{st.session_state.supervision_max_retries})")
                    full_response = ""

                    try:
                        st.session_state.chat_session = load_main_model(current_instruction).start_chat(
                            history=convert_to_gemini_format(st.session_state.chat_history) 
                        )
                        response_stream = st.session_state.chat_session.send_message(regen_contents_for_model, stream=True)
                        
                        for chunk in response_stream:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ")
                        message_placeholder.markdown(full_response)

                        # --- Supervisor í‰ê°€ (ì¬ìƒì„±) ---
                        total_score = 0
                        supervisor_feedback_list = []
                        
                        for i in range(st.session_state.supervisor_count):
                            score = evaluate_response(
                                user_input=previous_user_message_content,
                                chat_history=st.session_state.chat_history, # Supervisorì—ê²ŒëŠ” í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ íˆìŠ¤í† ë¦¬ ì œê³µ
                                system_instruction=current_instruction,
                                ai_response=full_response
                            )
                            total_score += score
                            supervisor_feedback_list.append(f"Supervisor {i+1} ì ìˆ˜: {score}ì ")
                        
                        avg_score = total_score / st.session_state.supervisor_count
                        
                        st.info(f"ì¬ìƒì„± í‰ê·  Supervisor ì ìˆ˜: {avg_score:.2f}ì ")
                        for feedback in supervisor_feedback_list:
                            st.info(feedback)

                        if avg_score >= st.session_state.supervision_threshold:
                            best_ai_response = full_response
                            highest_score = avg_score
                            st.success("âœ… ì¬ìƒì„± ë‹µë³€ì´ Supervision í†µê³¼ ê¸°ì¤€ì„ ë§Œì¡±í•©ë‹ˆë‹¤!")
                            break # í†µê³¼í–ˆìœ¼ë¯€ë¡œ ë£¨í”„ ì¢…ë£Œ
                        else:
                            st.warning(f"âŒ ì¬ìƒì„± ë‹µë³€ì´ Supervision í†µê³¼ ê¸°ì¤€({st.session_state.supervision_threshold}ì )ì„ ë§Œì¡±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                            if avg_score > highest_score: # í˜„ì¬ ë‹µë³€ì´ ì´ì „ ìµœê³  ì ìˆ˜ë³´ë‹¤ ë†’ìœ¼ë©´ ì €ì¥
                                highest_score = avg_score
                                best_ai_response = full_response
                    
                    except Exception as e:
                        st.error(f"ì¬ìƒì„± ë©”ì‹œì§€ ìƒì„± ë˜ëŠ” í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                        break
            else: # Supervision is OFF for Regeneration
                message_placeholder.markdown("ğŸ¤– ë‹µë³€ ì¬ìƒì„± ì¤‘...")
                full_response = ""
                try:
                    st.session_state.chat_session = load_main_model(current_instruction).start_chat(
                        history=convert_to_gemini_format(st.session_state.chat_history)
                    )
                    response_stream = st.session_state.chat_session.send_message(regen_contents_for_model, stream=True)
                    
                    for chunk in response_stream:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                    message_placeholder.markdown(full_response)
                    best_ai_response = full_response # Directly assign the response
                    highest_score = 100 # Placeholder score, not actually used for display
                except Exception as e:
                    st.error(f"ì¬ìƒì„± ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

            # --- Supervision/Single-pass Logic í›„ ìµœì¢… ì¬ìƒì„± AI ë‹µë³€ ì²˜ë¦¬ ---
            if best_ai_response:
                st.session_state.chat_history.append(("model", best_ai_response)) # ìƒˆë¡œìš´ AI ë©”ì‹œì§€ ì¶”ê°€
                message_placeholder.markdown(best_ai_response) # ìµœì¢…ì ìœ¼ë¡œ ì„ íƒëœ ë‹µë³€ì„ ë‹¤ì‹œ í‘œì‹œ
                if st.session_state.use_supervision:
                    st.toast(f"ì¬ìƒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì¢… ì ìˆ˜: {highest_score:.2f}ì ", icon="ğŸ‘")
                else:
                    st.toast("ì¬ìƒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ‘")
            else:
                st.error("ëª¨ë“  ì¬ì‹œë„ í›„ì—ë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì¬ìƒì„± ë‹µë³€ì„ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ì „ ìµœê³  ì ìˆ˜ ë‹µë³€ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                if highest_score != -1: # ì ì–´ë„ í•˜ë‚˜ì˜ ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´
                    st.session_state.chat_history.append(("model", best_ai_response))
                    message_placeholder.markdown(best_ai_response)
                    if st.session_state.use_supervision:
                        st.toast(f"ìµœê³  ì ìˆ˜ ì¬ìƒì„± ë‹µë³€ì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì ìˆ˜: {highest_score:.2f}ì ", icon="â—")
                    else:
                        st.toast("ìµœê³  ì ìˆ˜ ì¬ìƒì„± ë‹µë³€ì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="â—") # No score if not using supervision
                else: # ì–´ë–¤ ë‹µë³€ë„ ìƒì„±ë˜ì§€ ëª»í•œ ê²½ìš°
                    st.session_state.chat_history.append(("model", "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì— ëŒ€í•´ ë‹µë³€ì„ ì¬ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
                    message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì— ëŒ€í•´ ë‹µë³€ì„ ì¬ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.session_state.regenerate_requested = False # ì¬ìƒì„± í”Œë˜ê·¸ ì¬ì„¤ì •
            st.session_state.is_generating = False # ìƒì„± í”Œë˜ê·¸ ì¬ì„¤ì •
            
            # ì„±ê³µì ì¸ ì¬ìƒì„± í›„ Firestoreì— ë°ì´í„° ì €ì¥
            st.session_state.saved_sessions[st.session_state.current_title] = st.session_state.chat_history.copy()
            current_instruction_for_save = st.session_state.temp_system_instruction if st.session_state.temp_system_instruction is not None else st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
            st.session_state.system_instructions[st.session_state.current_title] = current_instruction_for_save
            save_user_data_to_firestore(st.session_state.user_id)
            st.rerun() # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë‹¤ì‹œ ì‹¤í–‰


# AI generation trigger logic
# Trigger if user_prompt is entered (Enter key) OR if an image is uploaded and user_prompt is empty
if user_prompt is not None and not st.session_state.is_generating:
    if user_prompt != "" or st.session_state.uploaded_file is not None:
        st.session_state.chat_history.append(("user", user_prompt)) # Add prompt (can be empty string)
        st.session_state.is_generating = True
        # Store the current user input (text and image) for potential regeneration
        st.session_state.last_user_input_for_regen = {
            "text": user_prompt,
            "image": st.session_state.uploaded_file.getvalue() if st.session_state.uploaded_file else None,
            "mime_type": st.session_state.uploaded_file.type if st.session_state.uploaded_file else None
        }
        st.rerun() # Update UI and start generation immediately after prompt submission

# --- AI Response Generation and Display Logic ---
# This block runs only when AI is generating a response (and not regenerating).
if st.session_state.is_generating and not st.session_state.regenerate_requested:
    with chat_display_container: # Display generating message within the chat area
        # The user message is already displayed by the main history loop
        with st.chat_message("ai"):
            message_placeholder = st.empty() # Placeholder for streaming response
            
            best_ai_response = "" # Supervision í›„ ê°€ì¥ ì¢‹ì€ ë‹µë³€ì„ ì €ì¥
            highest_score = -1    # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ì €ì¥
            
            current_user_prompt_text = st.session_state.chat_history[-1][1] # ë§ˆì§€ë§‰ ì¶”ê°€ëœ ì‚¬ìš©ì ë©”ì‹œì§€ í…ìŠ¤íŠ¸
            current_user_image_data = st.session_state.last_user_input_for_regen["image"]
            current_user_image_mime = st.session_state.last_user_input_for_regen["mime_type"]

            # ëª¨ë¸ì— ë³´ë‚¼ ì´ˆê¸° ì½˜í…ì¸ ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
            initial_contents_for_model = [current_user_prompt_text]
            if current_user_image_data:
                initial_contents_for_model.append({"inline_data": {"mime_type": current_user_image_mime, "data": current_user_image_data}})

            current_instruction = st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
            history_for_main_model = st.session_state.chat_history[:-1]

            if st.session_state.use_supervision: # Supervision í† ê¸€ì´ ì¼œì ¸ ìˆì„ ë•Œë§Œ ë£¨í”„ ì‹¤í–‰
                attempt_count = 0
                while attempt_count < st.session_state.supervision_max_retries:
                    attempt_count += 1
                    message_placeholder.markdown(f"ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘... (ì‹œë„: {attempt_count}/{st.session_state.supervision_max_retries})")
                    full_response = "" # í˜„ì¬ ì‹œë„ì—ì„œ ëª¨ë¸ì´ ìƒì„±í•œ ë‹µë³€

                    try:
                        # ìƒˆë¡œìš´ ë‹µë³€ ìƒì„±ì„ ìœ„í•´ chat_sessionì„ ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ë‹¤ì‹œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                        st.session_state.chat_session = load_main_model(current_instruction).start_chat(
                            history=convert_to_gemini_format(history_for_main_model)
                        )

                        # ëª¨ë¸ì— í˜„ì¬ ì‚¬ìš©ì ì…ë ¥(ë° ì´ë¯¸ì§€)ì„ ì „ì†¡í•˜ì—¬ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
                        response_stream = st.session_state.chat_session.send_message(initial_contents_for_model, stream=True)
                        
                        for chunk in response_stream:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ") # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì»¤ì„œ í‘œì‹œ
                        message_placeholder.markdown(full_response) # ìµœì¢… ë‹µë³€ í‘œì‹œ (ì»¤ì„œ ì—†ì´)

                        # --- Supervisor í‰ê°€ ì‹œì‘ ---
                        total_score = 0
                        supervisor_feedback_list = []
                        
                        for i in range(st.session_state.supervisor_count):
                            score = evaluate_response(
                                user_input=current_user_prompt_text,
                                chat_history=st.session_state.chat_history[:-1], # Supervisorì—ê²ŒëŠ” í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì œì™¸í•œ íˆìŠ¤í† ë¦¬ ì œê³µ
                                system_instruction=current_instruction,
                                ai_response=full_response
                            )
                            total_score += score
                            supervisor_feedback_list.append(f"Supervisor {i+1} ì ìˆ˜: {score}ì ")
                        
                        avg_score = total_score / st.session_state.supervisor_count
                        
                        st.info(f"í‰ê·  Supervisor ì ìˆ˜: {avg_score:.2f}ì ")
                        for feedback in supervisor_feedback_list:
                            st.info(feedback)

                        if avg_score >= st.session_state.supervision_threshold:
                            best_ai_response = full_response
                            highest_score = avg_score
                            st.success("âœ… ë‹µë³€ì´ Supervision í†µê³¼ ê¸°ì¤€ì„ ë§Œì¡±í•©ë‹ˆë‹¤!")
                            break # í†µê³¼í–ˆìœ¼ë¯€ë¡œ ë£¨í”„ ì¢…ë£Œ
                        else:
                            st.warning(f"âŒ ë‹µë³€ì´ Supervision í†µê³¼ ê¸°ì¤€({st.session_state.supervision_threshold}ì )ì„ ë§Œì¡±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                            if avg_score > highest_score: # í˜„ì¬ ë‹µë³€ì´ ì´ì „ ìµœê³  ì ìˆ˜ë³´ë‹¤ ë†’ìœ¼ë©´ ì €ì¥
                                highest_score = avg_score
                                best_ai_response = full_response

                    except Exception as e:
                        st.error(f"ë©”ì‹œì§€ ìƒì„± ë˜ëŠ” í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                        st.session_state.uploaded_file = None # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì—…ë¡œë“œëœ íŒŒì¼ ì´ˆê¸°í™”
                        break # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë£¨í”„ ì¢…ë£Œ
            else: # Supervision is OFF (Supervision í† ê¸€ì´ êº¼ì ¸ ìˆì„ ë•Œ)
                message_placeholder.markdown("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
                full_response = ""
                try:
                    st.session_state.chat_session = load_main_model(current_instruction).start_chat(
                        history=convert_to_gemini_format(history_for_main_model)
                    )
                    response_stream = st.session_state.chat_session.send_message(initial_contents_for_model, stream=True)
                    
                    for chunk in response_stream:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                    message_placeholder.markdown(full_response)
                    best_ai_response = full_response # Supervisionì´ êº¼ì ¸ ìˆìœ¼ë©´ ë°”ë¡œ ì´ ë‹µë³€ì„ ì±„íƒ
                    highest_score = 100 # Supervisionì´ ì•„ë‹ˆë¯€ë¡œ ì ìˆ˜ëŠ” ì˜ë¯¸ ì—†ì§€ë§Œ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¼ê´€ì„±ì„ ìœ„í•´ ì„ì˜ ê°’ ë¶€ì—¬
                except Exception as e:
                    st.error(f"ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.session_state.uploaded_file = None

            # --- Supervision/Single-pass Logic í›„ ìµœì¢… AI ë‹µë³€ ì²˜ë¦¬ ---
            if best_ai_response:
                st.session_state.chat_history.append(("model", best_ai_response))
                message_placeholder.markdown(best_ai_response)
                if st.session_state.use_supervision: # Supervision í™œì„±í™” ì—¬ë¶€ì— ë”°ë¼ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ ë³€ê²½
                    st.toast(f"ëŒ€í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì¢… ì ìˆ˜: {highest_score:.2f}ì ", icon="ğŸ‘")
                else:
                    st.toast("ëŒ€í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ‘") # Supervision ë¹„í™œì„±í™” ì‹œ ì ìˆ˜ í‘œì‹œ ì•ˆ í•¨
            else:
                st.error("ëª¨ë“  ì¬ì‹œë„ í›„ì—ë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ì „ ìµœê³  ì ìˆ˜ ë‹µë³€ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                if highest_score != -1: # ì ì–´ë„ í•˜ë‚˜ì˜ ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ (ìµœê³  ì ìˆ˜ ë‹µë³€ì´ ìˆìœ¼ë©´)
                    st.session_state.chat_history.append(("model", best_ai_response))
                    message_placeholder.markdown(best_ai_response)
                    if st.session_state.use_supervision: # Supervision í™œì„±í™” ì—¬ë¶€ì— ë”°ë¼ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ ë³€ê²½
                        st.toast(f"ìµœê³  ì ìˆ˜ ë‹µë³€ì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì ìˆ˜: {highest_score:.2f}ì ", icon="â—")
                    else:
                        st.toast("ìµœê³  ì ìˆ˜ ë‹µë³€ì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="â—") # Supervision ë¹„í™œì„±í™” ì‹œ ì ìˆ˜ í‘œì‹œ ì•ˆ í•¨
                else: # ì–´ë–¤ ë‹µë³€ë„ ìƒì„±ë˜ì§€ ëª»í•œ ê²½ìš°
                    st.session_state.chat_history.append(("model", "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì— ëŒ€í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
                    message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì— ëŒ€í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.session_state.uploaded_file = None
            st.session_state.is_generating = False

            # ì²« ìƒí˜¸ì‘ìš© ì‹œ ëŒ€í™” ì œëª© ìë™ ìƒì„± (Supervision ë£¨í”„ ì™„ë£Œ í›„)
            if st.session_state.current_title == "ìƒˆë¡œìš´ ëŒ€í™”" and \
               len(st.session_state.chat_history) >= 2 and \
               st.session_state.chat_history[-2][0] == "user" and st.session_state.chat_history[-1][0] == "model":
                with st.spinner("ëŒ€í™” ì œëª© ìƒì„± ì¤‘..."):
                    try:
                        summary_prompt_text = st.session_state.chat_history[-2][1] # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
                        summary = summary_model.generate_content(f"ë‹¤ìŒ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•´ì„œ ëŒ€í™” ì œëª©ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ (í•œ ë¬¸ì¥, 30ì ì´ë‚´):\n\n{summary_prompt_text}")
                        original_title = summary.text.strip().replace("\n", " ").replace('"', '')
                        if not original_title or len(original_title) > 30: # 30ì ì´ìƒì´ë©´ ê¸°ë³¸ ì œëª© ì‚¬ìš©
                            original_title = "ìƒˆë¡œìš´ ëŒ€í™”"
                    except Exception as e:
                        print(f"ì œëª© ìƒì„± ì˜¤ë¥˜: {e}. ê¸°ë³¸ ì œëª© ì‚¬ìš©.")
                        original_title = "ìƒˆë¡œìš´ ëŒ€í™”"

                    title_key = original_title
                    count = 1
                    while title_key in st.session_state.saved_sessions:
                        title_key = f"{original_title} ({count})"
                        count += 1
                    st.session_state.current_title = title_key
                    st.toast(f"ëŒ€í™” ì œëª©ì´ '{title_key}'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ“")

            # ì„±ê³µì ì¸ ìƒì„± í›„ Firestoreì— ë°ì´í„° ì €ì¥ (Supervision ë£¨í”„ ì™„ë£Œ í›„)
            st.session_state.saved_sessions[st.session_state.current_title] = st.session_state.chat_history.copy()
            current_instruction_for_save = st.session_state.temp_system_instruction if st.session_state.temp_system_instruction is not None else st.session_state.system_instructions.get(st.session_state.current_title, default_system_instruction)
            st.session_state.system_instructions[st.session_state.current_title] = current_instruction_for_save
            save_user_data_to_firestore(st.session_state.user_id)
            
            st.rerun() # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë‹¤ì‹œ ì‹¤í–‰

